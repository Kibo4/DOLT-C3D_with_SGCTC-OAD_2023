{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from Tools.Voxelizer import MapperIdVoxelizer\n",
    "pathDB = \"C:\\workspace2\\Datasets\\Chalearn\\\\\"\n",
    "separator = \"\\\\\"\n",
    "attribute = \"R4D_10x10_split200_rctc_customRec_presence_withOut\"  # \"RelativeDraw0_4D_datasetSave70\"#\"RelativeCBDraw0_datasetSave60_notOneHot\" #\"RelativeCBDraw0_datasetSave60\" #RelativeDraw0_4D_datasetSave60\" #CB\n",
    "pathPreprocessedData = pathDB + \"PreprocessedData\" + attribute + separator\n",
    "pathPreprocessedValidData = pathDB + \"PreprocessedDataValid\" + attribute + separator\n",
    "pathPreprocessedTestData = pathDB + \"PreprocessedDataTest\" + attribute + separator\n",
    "pathPreprocessedLabel = pathDB + \"PreprocessedLabel\" + attribute + separator\n",
    "pathLabelOriginal = pathDB + \"Label\" + separator\n",
    "pathCuDiSplit = pathDB + \"CuDiSplit\" + attribute + separator\n",
    "\n",
    "dbInfoFileName = \"db.info\"\n",
    "hyperParamPreproFileName = \"hyperparams_preprocess.info\"\n",
    "pathLog = pathDB + \"Log\" + separator\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "\n",
    "# configAll = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "# CUDA_VISIBLE_DEVICES=\"\"\n",
    "# %% md\n",
    "### Read db infos and hyperparameters\n",
    "\n",
    "# %%\n",
    "\n",
    "# database info (device, protocol path, nbClass..) IN PREPROCESSED FOLDER\n",
    "finfo = open(pathPreprocessedData + dbInfoFileName, \"r\")\n",
    "DBinfos = eval(\"\\n\".join(finfo.readlines()))\n",
    "finfo.close()\n",
    "\n",
    "# hyperparemters linked to the preprocessing : size of voxelization image, thresholds, subsampling...\n",
    "finfo = open(pathPreprocessedData + hyperParamPreproFileName, \"r\")\n",
    "hyperparams = eval(\"\\n\".join(finfo.readlines()))\n",
    "finfo.close()\n",
    "\n",
    "idVoxelisation = hyperparams[\"modeVoxelisation\"]\n",
    "dimensionsImage = np.array(list(hyperparams[\"dimensionImage\"]))\n",
    "thresholdCuDi = hyperparams[\"thresholdCuDi\"]\n",
    "toleranceMoveThreshold = hyperparams[\"toleranceMoveThreshold\"]\n",
    "thresholdToleranceDrawing = hyperparams[\"thresholdToleranceDrawing\"]\n",
    "jointsSelected = hyperparams[\"jointSelection\"]\n",
    "nbSkeleton = DBinfos[\"nbSkeleton\"]\n",
    "nbClass = DBinfos[\"nbClass\"]\n",
    "pathProtocolFolder = pathDB + \"Split\" + separator\n",
    "is4D = \"4D\" in pathPreprocessedData\n",
    "if nbSkeleton == 1:\n",
    "    boxSize = MapperIdVoxelizer.map1sq(idVoxelisation, dimensionsImage, toleranceMoveThreshold, thresholdCuDi,\n",
    "                                       thresholdToleranceDrawing,\n",
    "                                       jointsSelected).finalSizeBox()\n",
    "else:\n",
    "    boxSize = MapperIdVoxelizer.map2sq(idVoxelisation, dimensionsImage, toleranceMoveThreshold, thresholdCuDi,\n",
    "                                       thresholdToleranceDrawing,\n",
    "                                       jointsSelected).finalSizeBox()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read config file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# database info (device, protocol path, nbClass..)\n",
    "finfo = open(pathDB+dbInfoFileName, \"r\")\n",
    "DBinfos = eval(\"\\n\".join(finfo.readlines()))\n",
    "finfo.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "datasetTrain = tf.data.experimental.load(pathPreprocessedData)\n",
    "datasetValid = tf.data.experimental.load(pathPreprocessedValidData)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "ds  = list(iter(datasetTrain))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10 10  8], shape=(3,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 2 2]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0 1]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 0 0]]], shape=(10, 10, 8), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for data in ds:\n",
    "    seq = data[0]\n",
    "    compactZ = tf.math.argmax(seq,axis=3)\n",
    "    print(tf.shape(compactZ))\n",
    "    print(compactZ)\n",
    "\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}